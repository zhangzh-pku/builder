<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="1" failures="4" skipped="0" tests="19" time="507.152" timestamp="2023-11-29T13:22:42.057436" hostname="LAPTOP-GD9TV0PR"><testcase classname="apps.api.tests.test_datasets" name="test_create_dataset" time="8.147" /><testcase classname="apps.api.tests.test_datasets" name="test_delete_dataset" time="0.744" /><testcase classname="apps.api.tests.test_datasets" name="test_get_dataset" time="19.811" /><testcase classname="apps.api.tests.test_datasets" name="test_update_dataset_with_annotated_data" time="43.540" /><testcase classname="apps.api.tests.test_datasets" name="test_update_dataset" time="82.532" /><testcase classname="apps.api.tests.test_datasets" name="test_update_dataset_preview" time="15.137" /><testcase classname="apps.api.tests.test_datasets" name="test_retrieve_document_segments" time="18.542" /><testcase classname="apps.api.tests.test_datasets" name="test_retrieve_document_segments_with_query" time="18.671" /><testcase classname="apps.api.tests.test_datasets" name="test_add_segments" time="10.780"><failure message="sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint &quot;datasets_pkey&quot;&#10;DETAIL:  Key (id)=(test_add_segment) already exists.&#10;&#10;[SQL: INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)]&#10;[parameters: {'id': 'test_add_segment', 'documents': '[{&quot;uid&quot;: &quot;test_add_segment_uid&quot;, &quot;url&quot;: &quot;https://storage.googleapis.com/context-builder/public-tmp/J6D08G9I5ja0.pdf&quot;, &quot;type&quot;: &quot;pdf&quot;, &quot;page_size&quot;: 4, &quot;split_option&quot;: {&quot;split_type&quot;: &quot;character&quot;, &quot;chunk_size&quot;: 500, &quot;chunk_overlap&quot;: 0}, &quot;content_size&quot;: 1514, &quot;hundredth_ids&quot;: []}]', 'retrieval': '{}'}]&#10;(Background on this error at: https://sqlalche.me/e/20/gkpj)">self = &lt;sqlalchemy.engine.base.Connection object at 0x7f3d9904a8f0&gt;
dialect = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7f3da1127e80&gt;
context = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7f3d99049e40&gt;
statement = &lt;sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7f3d98376bf0&gt;
parameters = [{'documents': '[{"uid": "test_add_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D...: 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'id': 'test_add_segment', 'retrieval': '{}'}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
&gt;                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7f3da1127e80&gt;
cursor = &lt;cursor object at 0x7f3d9a766110; closed: -1&gt;
statement = 'INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)'
parameters = {'documents': '[{"uid": "test_add_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D0...": 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'id': 'test_add_segment', 'retrieval': '{}'}
context = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7f3d99049e40&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)
E       psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "datasets_pkey"
E       DETAIL:  Key (id)=(test_add_segment) already exists.

/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921: UniqueViolation

The above exception was the direct cause of the following exception:

    def test_add_segments():
        test_dataset_id = 'test_add_segment'
        test_document_uid = "test_add_segment_uid"
        test_dataset = Dataset(
            id=test_dataset_id,
            documents=[
                {
                    "uid": test_document_uid,
                    "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D08G9I5ja0.pdf",
                    "type": "pdf",
                    "split_option": {
                        "split_type": "character",
                        "chunk_size": 500,
                        "chunk_overlap": 0
                    }
                }
            ]
        )
&gt;       dataset_manager.save_dataset(test_dataset)

apps/api/tests/test_datasets.py:317: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
apps/api/models/base/base.py:46: in wrapper
    raise e
apps/api/models/base/base.py:40: in wrapper
    results = session.execute(query)
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2262: in execute
    return self._execute_internal(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2153: in _execute_internal
    result = conn.execute(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1412: in execute
    return meth(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:515: in _execute_on_connection
    return connection._execute_clauseelement(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1635: in _execute_clauseelement
    ret = self._execute_context(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1844: in _execute_context
    return self._exec_single_context(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1984: in _exec_single_context
    self._handle_dbapi_exception(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7f3da1127e80&gt;
cursor = &lt;cursor object at 0x7f3d9a766110; closed: -1&gt;
statement = 'INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)'
parameters = {'documents': '[{"uid": "test_add_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D0...": 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'id': 'test_add_segment', 'retrieval': '{}'}
context = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7f3d99049e40&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)
E       sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "datasets_pkey"
E       DETAIL:  Key (id)=(test_add_segment) already exists.
E       
E       [SQL: INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)]
E       [parameters: {'id': 'test_add_segment', 'documents': '[{"uid": "test_add_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D08G9I5ja0.pdf", "type": "pdf", "page_size": 4, "split_option": {"split_type": "character", "chunk_size": 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'retrieval': '{}'}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921: IntegrityError</failure></testcase><testcase classname="apps.api.tests.test_datasets" name="test_edit_segment" time="10.973"><failure message="sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint &quot;datasets_pkey&quot;&#10;DETAIL:  Key (id)=(test_edit_segment) already exists.&#10;&#10;[SQL: INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)]&#10;[parameters: {'id': 'test_edit_segment', 'documents': '[{&quot;uid&quot;: &quot;test_edit_segment_uid&quot;, &quot;url&quot;: &quot;https://storage.googleapis.com/context-builder/public-tmp/J6D08G9I5ja0.pdf&quot;, &quot;type&quot;: &quot;pdf&quot;, &quot;page_size&quot;: 4, &quot;split_option&quot;: {&quot;split_type&quot;: &quot;character&quot;, &quot;chunk_size&quot;: 500, &quot;chunk_overlap&quot;: 0}, &quot;content_size&quot;: 1514, &quot;hundredth_ids&quot;: []}]', 'retrieval': '{}'}]&#10;(Background on this error at: https://sqlalche.me/e/20/gkpj)">self = &lt;sqlalchemy.engine.base.Connection object at 0x7f3d9814e530&gt;
dialect = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7f3da1127e80&gt;
context = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7f3d9814f760&gt;
statement = &lt;sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7f3d98376bf0&gt;
parameters = [{'documents': '[{"uid": "test_edit_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6... 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'id': 'test_edit_segment', 'retrieval': '{}'}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
&gt;                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7f3da1127e80&gt;
cursor = &lt;cursor object at 0x7f3d9a766f20; closed: -1&gt;
statement = 'INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)'
parameters = {'documents': '[{"uid": "test_edit_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D...: 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'id': 'test_edit_segment', 'retrieval': '{}'}
context = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7f3d9814f760&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)
E       psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "datasets_pkey"
E       DETAIL:  Key (id)=(test_edit_segment) already exists.

/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921: UniqueViolation

The above exception was the direct cause of the following exception:

    def test_edit_segment():
        test_dataset_id = 'test_edit_segment'
        test_document_uid = "test_edit_segment_uid"
        test_document_url = "https://storage.googleapis.com/context-builder/public-tmp/J6D08G9I5ja0.pdf"
        test_segment_id = f"{test_dataset_id}-{test_document_url}-0"
        test_dataset = Dataset(
            id=test_dataset_id,
            documents=[
                {
                    "uid": test_document_uid,
                    "url": test_document_url,
                    "type": "pdf",
                    "split_option": {
                        "split_type": "character",
                        "chunk_size": 500,
                        "chunk_overlap": 0
                    }
                }
            ]
        )
&gt;       dataset_manager.save_dataset(test_dataset)

apps/api/tests/test_datasets.py:356: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
apps/api/models/base/base.py:46: in wrapper
    raise e
apps/api/models/base/base.py:40: in wrapper
    results = session.execute(query)
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2262: in execute
    return self._execute_internal(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2153: in _execute_internal
    result = conn.execute(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1412: in execute
    return meth(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:515: in _execute_on_connection
    return connection._execute_clauseelement(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1635: in _execute_clauseelement
    ret = self._execute_context(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1844: in _execute_context
    return self._exec_single_context(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1984: in _exec_single_context
    self._handle_dbapi_exception(
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7f3da1127e80&gt;
cursor = &lt;cursor object at 0x7f3d9a766f20; closed: -1&gt;
statement = 'INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)'
parameters = {'documents': '[{"uid": "test_edit_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D...: 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'id': 'test_edit_segment', 'retrieval': '{}'}
context = &lt;sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7f3d9814f760&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)
E       sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "datasets_pkey"
E       DETAIL:  Key (id)=(test_edit_segment) already exists.
E       
E       [SQL: INSERT INTO datasets (id, documents, retrieval) VALUES (%(id)s, %(documents)s, %(retrieval)s)]
E       [parameters: {'id': 'test_edit_segment', 'documents': '[{"uid": "test_edit_segment_uid", "url": "https://storage.googleapis.com/context-builder/public-tmp/J6D08G9I5ja0.pdf", "type": "pdf", "page_size": 4, "split_option": {"split_type": "character", "chunk_size": 500, "chunk_overlap": 0}, "content_size": 1514, "hundredth_ids": []}]', 'retrieval': '{}'}]
E       (Background on this error at: https://sqlalche.me/e/20/gkpj)

/home/lxwww/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921: IntegrityError</failure></testcase><testcase classname="apps.api.tests.test_datasets" name="test_delete_segment" time="186.273" /><testcase classname="apps.api.tests.test_datasets" name="test_dataset_integration" time="58.778" /><testcase classname="apps.api.tests.test_models" name="test_get_model" time="1.622" /><testcase classname="apps.api.tests.test_models" name="test_get_models" time="0.030"><failure message="assert 405 == 200&#10; +  where 405 = &lt;Response [405 Method Not Allowed]&gt;.status_code">def test_get_models():
        """
        Tests the GET /v1/models endpoint.
        The endpoint is supposed to return all models.
        """
        response = client.get("/v1/models")
    
        # The endpoint should return with a 200 OK status
&gt;       assert response.status_code == 200
E       assert 405 == 200
E        +  where 405 = &lt;Response [405 Method Not Allowed]&gt;.status_code

apps/api/tests/test_models.py:44: AssertionError</failure></testcase><testcase classname="apps.api.tests.test_models" name="test_create_model" time="0.765" /><testcase classname="apps.api.tests.test_models" name="test_update_model" time="0.799" /><testcase classname="apps.api.tests.test_models" name="test_delete_model" time="0.887" /><testcase classname="apps.api.tests.test_workflow" name="test_qa_chat" time="0.029"><error message="failed on setup with &quot;AttributeError: 'DatasetManager' object has no attribute 'update_dataset'&quot;">@pytest.fixture
    def test_data():
        llm1 = LLM(
            name="gpt-3.5-turbo",
            max_tokens=1000,
            temperature=0.9,
            top_p=1,
            frequency_penalty=0,
            presence_penalty=0,
            api_key=OPENAI_API_KEY,
        )
        document = Document(
            uid="test_document_1",
            url="https://storage.googleapis.com/context-builder/public-tmp/kxPvcLZ1BzRC.pdf",
            type="pdf",
            page_size=2,
        )
        document.page_size = 2
        template1 = Prompt(
            template="""Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.
    
    Follow Up Input: {question}
    Standalone question:"""
        )
        dataset = Dataset(
            id="test_dataset_1",
            documents=[document],
        )
    
        updated_dict = dataset.dict()
        updated_dict.pop("id")
&gt;       dataset_manager.update_dataset(dataset.id, updated_dict)
E       AttributeError: 'DatasetManager' object has no attribute 'update_dataset'

apps/api/tests/test_workflow.py:48: AttributeError</error></testcase><testcase classname="apps.api.tests.test_workflow" name="test_conversation_chat" time="4.048"><failure message="pydantic.error_wrappers.ValidationError: 1 validation error for ChatOpenAI&#10;__root__&#10;  Parameters {'api_key'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter. (type=value_error)">test_conversation = 'test_model_3', capfd = &lt;_pytest.capture.CaptureFixture object at 0x7f3d994a6aa0&gt;

    @pytest.mark.asyncio
    async def test_conversation_chat(test_conversation, capfd):
        session_id = uuid.uuid4().hex
        session_state_manager.save_session_state(
            session_id=session_id, model_id=test_conversation
        )
&gt;       async for response in send_message(
            [
                Messages(content="tell me the ans of 2^10", role="user"),
            ],
            session_id,
            filt=True,
        ):

apps/api/tests/test_workflow.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
apps/api/routers/chat.py:97: in send_message
    workflow = session_state_manager.get_workflow(session_id, model, disconnect_event)
apps/api/models/controller/session_state.py:103: in get_workflow
    workflow = Workflow(
apps/api/models/workflow/workflow.py:73: in __init__
    llm, prompt_template = self._prepare_llm_and_template(_chain)
apps/api/models/workflow/workflow.py:158: in _prepare_llm_and_template
    llm = ChatOpenAI(
/home/lxwww/.local/lib/python3.10/site-packages/langchain_core/load/serializable.py:97: in __init__
    super().__init__(**kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

&gt;   ???
E   pydantic.error_wrappers.ValidationError: 1 validation error for ChatOpenAI
E   __root__
E     Parameters {'api_key'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter. (type=value_error)

pydantic/main.py:342: ValidationError</failure></testcase></testsuite></testsuites>